{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import gensim\n",
        "import gensim.downloader\n",
        "import spacy\n",
        "import nltk\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import clustering_class\n",
        "from clustering_class import HierarchicalClustering\n",
        "\n",
        "\n",
        "\n",
        "random.seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import vectors & the nlp word interpreter\n",
        "glove_vectors = gensim.downloader.load('glove-wiki-gigaword-50')\n",
        "#nlp = spacy.load('en_core_web_trf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1161192"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.corpus import brown\n",
        "len(brown.words())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 41 verbs and 1619 nouns.\n"
          ]
        }
      ],
      "source": [
        "vocab_size = 5000\n",
        "tagged_vocab = nltk.pos_tag(glove_vectors.index_to_key[:vocab_size])\n",
        "\n",
        "verbs = [verb[0] for verb in tagged_vocab if verb[1]=='VB']\n",
        "nouns = [noun[0] for noun in tagged_vocab if noun[1]=='NN']\n",
        "#print(nouns)\n",
        "\n",
        "print(f\"There are {len(verbs)} verbs and {len(nouns)} nouns.\")\n",
        "\n",
        "verb_indices = [glove_vectors.index_to_key.index(verb) for verb in verbs]\n",
        "noun_indices = [glove_vectors.index_to_key.index(noun) for noun in nouns][2:]\n",
        "\n",
        "chosen_indices = set(noun_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3437\n"
          ]
        }
      ],
      "source": [
        "# trying to use wordnet instead\n",
        "from nltk.corpus import wordnet as wn\n",
        "wordnet_chosen_words=[]\n",
        "for word in glove_vectors.index_to_key[90:5000]:\n",
        "    tmp = wn.synsets(word)\n",
        "    if len([t.pos() for t in tmp if t.pos()=='n'])>=1:\n",
        "        wordnet_chosen_words.append(word)\n",
        "\n",
        "wordnet_chosen_indices = set([glove_vectors.key_to_index[word] for word in wordnet_chosen_words])\n",
        "print(len(wordnet_chosen_indices))\n",
        "#print(wordnet_chosen_words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting distance matrix progress:  20.0 %\n",
            "Setting distance matrix progress:  40.0 %\n",
            "Setting distance matrix progress:  60.0 %\n",
            "Setting distance matrix progress:  80.0 %\n",
            "Setting distance matrix progress:  100.0 %\n",
            "Finished setting distance matrix!\n",
            "Starting with the 1563 used and 3437 not used indices.\n",
            "Starting 1. hierarchical level.\n",
            "--- Finished sorting: len(not_used)=3436, new_proximity_size = 1763\n",
            "--- Finished sorting: len(not_used)=1672, new_proximity_size = 308\n",
            "--- Finished sorting: len(not_used)=1363, new_proximity_size = 178\n",
            "--- Finished sorting: len(not_used)=1184, new_proximity_size = 147\n",
            "--- Finished sorting: len(not_used)=1036, new_proximity_size = 79\n",
            "--- Finished sorting: len(not_used)=956, new_proximity_size = 77\n",
            "--- Finished sorting: len(not_used)=878, new_proximity_size = 74\n",
            "--- Finished sorting: len(not_used)=803, new_proximity_size = 57\n",
            "--- Finished sorting: len(not_used)=745, new_proximity_size = 54\n",
            "--- Finished sorting: len(not_used)=690, new_proximity_size = 43\n",
            "--- Finished sorting: len(not_used)=646, new_proximity_size = 37\n",
            "--- Finished sorting: len(not_used)=608, new_proximity_size = 34\n",
            "--- Finished sorting: len(not_used)=573, new_proximity_size = 33\n",
            "--- Finished sorting: len(not_used)=539, new_proximity_size = 33\n",
            "--- Finished sorting: len(not_used)=505, new_proximity_size = 29\n",
            "--- Finished sorting: len(not_used)=475, new_proximity_size = 26\n",
            "--- Finished sorting: len(not_used)=448, new_proximity_size = 25\n",
            "--- Finished sorting: len(not_used)=422, new_proximity_size = 24\n",
            "--- Finished sorting: len(not_used)=397, new_proximity_size = 24\n",
            "--- Finished sorting: len(not_used)=372, new_proximity_size = 21\n",
            "--- Finished sorting: len(not_used)=350, new_proximity_size = 20\n",
            "--- Finished sorting: len(not_used)=329, new_proximity_size = 16\n",
            "--- Finished sorting: len(not_used)=312, new_proximity_size = 15\n",
            "--- Finished sorting: len(not_used)=296, new_proximity_size = 15\n",
            "--- Finished sorting: len(not_used)=280, new_proximity_size = 14\n",
            "--- Finished sorting: len(not_used)=265, new_proximity_size = 14\n",
            "--- Finished sorting: len(not_used)=250, new_proximity_size = 17\n",
            "--- Finished sorting: len(not_used)=232, new_proximity_size = 13\n",
            "--- Finished sorting: len(not_used)=218, new_proximity_size = 12\n",
            "--- Finished sorting: len(not_used)=205, new_proximity_size = 11\n",
            "--- Finished sorting: len(not_used)=193, new_proximity_size = 11\n",
            "--- Finished sorting: len(not_used)=181, new_proximity_size = 10\n",
            "--- Finished sorting: len(not_used)=170, new_proximity_size = 9\n",
            "--- Finished sorting: len(not_used)=160, new_proximity_size = 9\n",
            "--- Finished sorting: len(not_used)=150, new_proximity_size = 7\n",
            "--- Finished sorting: len(not_used)=142, new_proximity_size = 7\n",
            "--- Finished sorting: len(not_used)=134, new_proximity_size = 7\n",
            "--- Finished sorting: len(not_used)=126, new_proximity_size = 6\n",
            "--- Finished sorting: len(not_used)=119, new_proximity_size = 5\n",
            "--- Finished sorting: len(not_used)=113, new_proximity_size = 5\n",
            "--- Finished sorting: len(not_used)=107, new_proximity_size = 5\n",
            "--- Finished sorting: len(not_used)=101, new_proximity_size = 4\n",
            "--- Finished sorting: len(not_used)=96, new_proximity_size = 4\n",
            "--- Finished sorting: len(not_used)=91, new_proximity_size = 4\n",
            "--- Finished sorting: len(not_used)=86, new_proximity_size = 4\n",
            "--- Finished sorting: len(not_used)=81, new_proximity_size = 3\n",
            "--- Finished sorting: len(not_used)=77, new_proximity_size = 3\n",
            "--- Finished sorting: len(not_used)=73, new_proximity_size = 3\n",
            "--- Finished sorting: len(not_used)=69, new_proximity_size = 2\n",
            "--- Finished sorting: len(not_used)=66, new_proximity_size = 2\n",
            "--- Finished sorting: len(not_used)=63, new_proximity_size = 2\n",
            "--- Finished sorting: len(not_used)=60, new_proximity_size = 3\n",
            "--- Finished sorting: len(not_used)=56, new_proximity_size = 2\n",
            "--- Finished sorting: len(not_used)=53, new_proximity_size = 2\n",
            "--- Finished sorting: len(not_used)=50, new_proximity_size = 1\n",
            "--- Finished sorting: len(not_used)=48, new_proximity_size = 1\n",
            "--- Finished sorting: len(not_used)=46, new_proximity_size = 1\n",
            "--- Finished sorting: len(not_used)=44, new_proximity_size = 1\n",
            "--- Finished sorting: len(not_used)=42, new_proximity_size = 1\n",
            "--- Finished sorting: len(not_used)=40, new_proximity_size = 1\n",
            "--- Finished sorting: len(not_used)=38, new_proximity_size = 1\n",
            "--- Finished sorting: len(not_used)=36, new_proximity_size = 1\n",
            "--- Finished sorting: len(not_used)=34, new_proximity_size = 1\n",
            "--- Finished sorting: len(not_used)=32, new_proximity_size = 1\n",
            "--- Finished sorting: len(not_used)=30, new_proximity_size = 1\n",
            "--- Finished sorting: len(not_used)=28, new_proximity_size = 1\n",
            "--- Finished sorting: len(not_used)=26, new_proximity_size = 1\n",
            "--- Finished sorting: len(not_used)=24, new_proximity_size = 1\n",
            "--- Finished sorting: len(not_used)=22, new_proximity_size = 1\n",
            "--- Finished sorting: len(not_used)=20, new_proximity_size = 0\n",
            "--- Finished sorting: len(not_used)=19, new_proximity_size = 0\n",
            "--- Finished sorting: len(not_used)=18, new_proximity_size = 0\n",
            "--- Finished sorting: len(not_used)=17, new_proximity_size = 0\n",
            "--- Finished sorting: len(not_used)=16, new_proximity_size = 0\n",
            "--- Finished sorting: len(not_used)=15, new_proximity_size = 0\n",
            "--- Finished sorting: len(not_used)=14, new_proximity_size = 0\n",
            "--- Finished sorting: len(not_used)=13, new_proximity_size = 0\n",
            "--- Finished sorting: len(not_used)=12, new_proximity_size = 0\n",
            "--- Finished sorting: len(not_used)=11, new_proximity_size = 0\n",
            "--- Finished sorting: len(not_used)=10, new_proximity_size = 0\n",
            "--- Finished sorting: len(not_used)=9, new_proximity_size = 0\n",
            "--- Finished sorting: len(not_used)=8, new_proximity_size = 0\n",
            "--- Finished sorting: len(not_used)=7, new_proximity_size = 0\n",
            "--- Finished sorting: len(not_used)=6, new_proximity_size = 0\n",
            "--- Finished sorting: len(not_used)=5, new_proximity_size = 0\n",
            "--- Finished sorting: len(not_used)=4, new_proximity_size = 0\n",
            "--- Finished sorting: len(not_used)=3, new_proximity_size = 0\n",
            "--- Finished sorting: len(not_used)=2, new_proximity_size = 0\n",
            "--- Finished sorting: len(not_used)=1, new_proximity_size = 0\n",
            "--- Finished sorting: len(not_used)=0, new_proximity_size = 0\n",
            "Starting 2. hierarchical level.\n",
            "--- Finished sorting: len(not_used)=89, new_proximity_size = 30\n",
            "--- Finished sorting: len(not_used)=58, new_proximity_size = 17\n",
            "--- Finished sorting: len(not_used)=40, new_proximity_size = 11\n",
            "--- Finished sorting: len(not_used)=28, new_proximity_size = 8\n",
            "--- Finished sorting: len(not_used)=19, new_proximity_size = 5\n",
            "--- Finished sorting: len(not_used)=13, new_proximity_size = 3\n",
            "--- Finished sorting: len(not_used)=9, new_proximity_size = 3\n",
            "--- Finished sorting: len(not_used)=5, new_proximity_size = 1\n",
            "--- Finished sorting: len(not_used)=3, new_proximity_size = 1\n",
            "--- Finished sorting: len(not_used)=1, new_proximity_size = 0\n",
            "--- Finished sorting: len(not_used)=0, new_proximity_size = 0\n",
            "Starting 3. hierarchical level.\n",
            "--- Finished sorting: len(not_used)=10, new_proximity_size = 8\n",
            "--- Finished sorting: len(not_used)=1, new_proximity_size = 1\n",
            "Starting 4. hierarchical level.\n",
            "--- Finished sorting: len(not_used)=1, new_proximity_size = 1\n",
            "Hierarchical clustering finished!\n"
          ]
        }
      ],
      "source": [
        "# re-import the clustering class in case it was changed.\n",
        "import importlib\n",
        "importlib.reload(clustering_class)\n",
        "\n",
        "# constants\n",
        "proximity_const = 1\n",
        "reducing_coef_const = 0\n",
        "increasing_proximity_const = 0.2\n",
        "\n",
        "# normed vectors\n",
        "reduced_vectors = glove_vectors.get_normed_vectors()[:vocab_size]\n",
        "\n",
        "hierarchical_clustering = clustering_class.HierarchicalClustering(\n",
        "    word_embedding=glove_vectors,\n",
        "    list_of_vectors=reduced_vectors,\n",
        "    chosen_indices=wordnet_chosen_indices,\n",
        "    initial_proximity=proximity_const,\n",
        "    proximity_reduc=reducing_coef_const,\n",
        "    initial_proximity_inc=increasing_proximity_const,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "\n",
        "better_hier_list, better_hier_list_w = hierarchical_clustering.get_better_list_of_hierarchical_orders()\n",
        "\n",
        "#try to give it the similarity measure instead?\n",
        "\n",
        "# named entity recognition, filter out \n",
        "# visualization of hierarchy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "chosen_words = np.asarray([reduced_vectors[i] for i in wordnet_chosen_indices])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "hierarchical_clustering.visualize_vectors(chosen_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "dict_keys(['graf'])"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i = 5\n",
        "\n",
        "print(len(better_hier_list[i].keys()))\n",
        "better_hier_list_w[i].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('theology', 0.7256718873977661), ('philosophical', 0.6801457405090332), ('psychology', 0.6610170006752014), ('sociology', 0.6346594095230103), ('metaphysics', 0.6081408858299255), ('literature', 0.5989529490470886), ('taught', 0.5878127217292786), ('mathematics', 0.5867588520050049), ('teaching', 0.5839151740074158), ('philosophies', 0.5800243020057678)]\n",
            "126\n",
            "science\n",
            "professor\n",
            "theory\n",
            "studied\n",
            "ideas\n",
            "religion\n",
            "teaching\n",
            "literature\n",
            "taught\n",
            "economics\n",
            "principles\n",
            "philosophy\n"
          ]
        }
      ],
      "source": [
        "glove_vectors.key_to_index['philosophy']\n",
        "print(glove_vectors.most_similar('philosophy'))\n",
        "print(len(hierarchical_clustering.which_in_proximity(0, 1)))\n",
        "for key in hierarchical_clustering.which_in_proximity(4044, 1):\n",
        "    print(glove_vectors.index_to_key[key])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So what would be a good measure of being a relevant word in a corpus of text. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(400000, 300)"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "glove_vectors.vectors.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
