{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.downloader\n",
    "import spacy\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import clustering_class\n",
    "from clustering_class import HierarchicalClustering\n",
    "\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import vectors & the nlp word interpreter\n",
    "glove_vectors = gensim.downloader.load(\"glove-wiki-gigaword-50\")\n",
    "# nlp = spacy.load('en_core_web_trf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "len(brown.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 5000\n",
    "tagged_vocab = nltk.pos_tag(glove_vectors.index_to_key[:vocab_size])\n",
    "\n",
    "verbs = [verb[0] for verb in tagged_vocab if verb[1] == \"VB\"]\n",
    "nouns = [noun[0] for noun in tagged_vocab if noun[1] == \"NN\"]\n",
    "# print(nouns)\n",
    "\n",
    "print(f\"There are {len(verbs)} verbs and {len(nouns)} nouns.\")\n",
    "\n",
    "verb_indices = [glove_vectors.index_to_key.index(verb) for verb in verbs]\n",
    "noun_indices = [glove_vectors.index_to_key.index(noun) for noun in nouns][2:]\n",
    "\n",
    "chosen_indices = set(noun_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to use wordnet instead\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "wordnet_chosen_words = []\n",
    "for word in glove_vectors.index_to_key[90:5000]:\n",
    "    tmp = wn.synsets(word)\n",
    "    if len([t.pos() for t in tmp if t.pos() == \"n\"]) >= 1:\n",
    "        wordnet_chosen_words.append(word)\n",
    "\n",
    "wordnet_chosen_indices = set(\n",
    "    [glove_vectors.key_to_index[word] for word in wordnet_chosen_words]\n",
    ")\n",
    "print(len(wordnet_chosen_indices))\n",
    "# print(wordnet_chosen_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-import the clustering class in case it was changed.\n",
    "import importlib\n",
    "\n",
    "importlib.reload(clustering_class)\n",
    "\n",
    "# constants\n",
    "proximity_const = 1\n",
    "reducing_coef_const = 0\n",
    "increasing_proximity_const = 0.2\n",
    "\n",
    "# normed vectors\n",
    "reduced_vectors = glove_vectors.get_normed_vectors()[:vocab_size]\n",
    "\n",
    "hierarchical_clustering = clustering_class.HierarchicalClustering(\n",
    "    word_embedding=glove_vectors,\n",
    "    list_of_vectors=reduced_vectors,\n",
    "    chosen_indices=wordnet_chosen_indices,\n",
    "    initial_proximity=proximity_const,\n",
    "    proximity_reduc=reducing_coef_const,\n",
    "    initial_proximity_inc=increasing_proximity_const,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "\n",
    "(\n",
    "    better_hier_list,\n",
    "    better_hier_list_w,\n",
    ") = hierarchical_clustering.get_better_list_of_hierarchical_orders()\n",
    "\n",
    "# try to give it the similarity measure instead?\n",
    "\n",
    "# named entity recognition, filter out\n",
    "# visualization of hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_words = np.asarray([reduced_vectors[i] for i in wordnet_chosen_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchical_clustering.visualize_vectors(chosen_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5\n",
    "\n",
    "print(len(better_hier_list[i].keys()))\n",
    "better_hier_list_w[i].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors.key_to_index[\"philosophy\"]\n",
    "print(glove_vectors.most_similar(\"philosophy\"))\n",
    "print(len(hierarchical_clustering.which_in_proximity(0, 1)))\n",
    "for key in hierarchical_clustering.which_in_proximity(4044, 1):\n",
    "    print(glove_vectors.index_to_key[key])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what would be a good measure of being a relevant word in a corpus of text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
